{
  "comments": [
    {
      "key": {
        "uuid": "3afa9182_d5544e23",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 327,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T09:51:19Z",
      "side": 1,
      "message": "Is it possible to add support for manual performance test result? I guess it is a tricky one.\n\nThe same test definition may produce multiple metrics. For these cases, we cannot use the test-name as test-case-name directly. And we need a mean to record \"test pass/fail measurement units\"\n\nTheoretically, all perf test can be automated. We should just leave it for now, just don\u0027t bother.",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_a0ab42d5",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 327,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2016-11-17T10:30:53Z",
      "side": 1,
      "message": "I think it can be done, but I would leave it out for now. Do we have any real cases like this for 16.12 release?",
      "parentUuid": "3afa9182_d5544e23",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_c095ae89",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 327,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T10:56:00Z",
      "side": 1,
      "message": "network perf and lapack would be the ones? I am afraid. Not sure if we can automate them. Should be possible, at least on the test target side.",
      "parentUuid": "3afa9182_a0ab42d5",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_8041e60d",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 327,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2016-11-17T11:27:53Z",
      "side": 1,
      "message": "lapac is a low priority for now. Netperf is high. If it\u0027s just one case, I guess we can live with manual editing. I\u0027ll try to hack a bit on that today. The problem as you noted is that they don\u0027t produce a single number. It gets complicated when we have to report more than 1 thing in manual testing.\n\nOn the other hand we might report pass/fail step by step. But than it would require expected result for each step separately. I did that before and there is little to none benefit from this approach. So I\u0027d rather not go this route again.",
      "parentUuid": "3afa9182_c095ae89",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_c0f80ec7",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 327,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T11:50:16Z",
      "side": 1,
      "message": "Then don\u0027t bother for the time being. I will try to automate netperf test. It may request a test client which should be setup before we run test on test target. \n\nOn the test target, should be not hard to automate netperf.",
      "parentUuid": "3afa9182_8041e60d",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_156896f4",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 522,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T09:51:19Z",
      "side": 1,
      "message": "Good point. Should we also print a warning if test_def doesn\u0027t exits? It happens when \n\n* test_def path in invalid(typo)\n* test_def not added to this repository yet(like 24h-stress-test)\n\nIn the current approach, test runner only support run tests located in this repository.",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_00b9762e",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 522,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2016-11-17T10:30:53Z",
      "side": 1,
      "message": "I\u0027ll add some warning message.",
      "parentUuid": "3afa9182_156896f4",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_f5806a8d",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 528,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T09:51:19Z",
      "side": 1,
      "message": "I don\u0027t know if it is a good idea to initiate TestRun class from TestDefinition class. If we try the below approach and remove get_test_run from TestDefinition class, will it look more straight forward?\n\nif args.kind \u003d\u003d \u0027manual\u0027:\n    test_run \u003d ManualTestRun(test, args)\nelif args.kind \u003d\u003d \u0027automated\u0027:\n    test_run \u003d AutomatedTestRun(test, args)\n\ntest_run.run()",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_807c4674",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 528,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2016-11-17T10:30:53Z",
      "side": 1,
      "message": "I think the whole approach is a bit weird here. I would do it differently with one entry point to the test plan (TestPlan class) that generates other bits (TestDefinition-\u003eTestRun-\u003eTestResults). Right now there are plenty potential points of failure. For example if TestRun fails to generate the output, ResultParser will fail. \n\nI would do it this way (pseudo code)\ntestplan \u003d TestPlan (args)\ntestdefs \u003d testplan.get_test_definitions()\nfor testdef in testdefs:\n    testrun \u003d testdef.get_test_run()\n    result \u003d testrun.execute()\n    if result.is_complete():\n         parser \u003d result.get_parser()\n         parser.parse_results()\n\nSeems we have contradicting approaches here :)",
      "parentUuid": "3afa9182_f5806a8d",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_e08c2a82",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 528,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T10:56:00Z",
      "side": 1,
      "message": "From my point of view\n\n* TestPlan validate test plan and returns test_list\n* TestDefinition convert testdef to run.sh\n* TestRun run \u0027run.sh\u0027 and produce stdout.log. \u0027run.sh\u0027 existence check is missing here.\n* TestParser parse \u0027stdout.log\u0027. \u0027stdout.log\u0027 existence check also is missing.\n\nI am a junior in python coding. If you think your approach make the most sense, we can do a bit refactoring.",
      "parentUuid": "3afa9182_807c4674",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_e0ba6a09",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 528,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2016-11-17T11:27:53Z",
      "side": 1,
      "message": "That all can be done as you write with a bit more modular approach as I proposed. Anyway, it works now and we need it working for the release. We can refactor after the sprint.\n\np.s. I don\u0027t consider myself a senior in this area :)",
      "parentUuid": "3afa9182_e08c2a82",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3afa9182_a0f502cd",
        "filename": "automated/utils/test-runner.py",
        "patchSetId": 3
      },
      "lineNbr": 528,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2016-11-17T11:50:16Z",
      "side": 1,
      "message": "+1, lets leave it for now.",
      "parentUuid": "3afa9182_e0ba6a09",
      "revId": "a42bd3d3e8b14308acf79fb38f59fa44257af579",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    }
  ]
}