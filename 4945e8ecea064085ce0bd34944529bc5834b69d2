{
  "comments": [
    {
      "key": {
        "uuid": "8bca3576_1d5e59b2",
        "filename": "automated/android/tradefed/tradefed-runner.py",
        "patchSetId": 2
      },
      "lineNbr": 115,
      "author": {
        "id": 1000015
      },
      "writtenOn": "2018-02-26T12:43:34Z",
      "side": 1,
      "message": "Is this 200 per module or 200 altogether that causes issues?",
      "revId": "4945e8ecea064085ce0bd34944529bc5834b69d2",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "07e47ad7_989ecc8c",
        "filename": "automated/android/tradefed/tradefed-runner.py",
        "patchSetId": 2
      },
      "lineNbr": 115,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2018-02-26T13:20:06Z",
      "side": 1,
      "message": "It is the total number of test failures in a run(a module or a test plan) causing issues.\n\nIn the job https://lkft.validation.linaro.org/results/128544/1_cts-opengl-v8a, the first module itself generated 4k+ test failures, which already is a killer.\n\nI would say we should remove these lines or use logger.debug instead. In the later case, we should set the default log level to info.\n\nIMHO, printing only part of the failures leads to more confusions. People who want to debug it can change log level to \u0027debug\u0027 for that or go to test attachment for full logs.",
      "parentUuid": "8bca3576_1d5e59b2",
      "revId": "4945e8ecea064085ce0bd34944529bc5834b69d2",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "556fe32c_7646f92b",
        "filename": "automated/android/tradefed/tradefed-runner.py",
        "patchSetId": 2
      },
      "lineNbr": 115,
      "author": {
        "id": 1000021
      },
      "writtenOn": "2018-02-26T15:06:19Z",
      "side": 1,
      "message": "hmm, before move to use atomic method, I would like to see the failures and the test result in one job. don\u0027t want to resubmit the job again just to get the failed test cases. for this opengl special case we need to do that though, but at the moment, we do not care much on the detailed failed test cases for opengl yet.",
      "parentUuid": "07e47ad7_989ecc8c",
      "revId": "4945e8ecea064085ce0bd34944529bc5834b69d2",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "3ee7272e_285b5e96",
        "filename": "automated/android/tradefed/tradefed-runner.py",
        "patchSetId": 2
      },
      "lineNbr": 115,
      "author": {
        "id": 1000096
      },
      "writtenOn": "2018-02-26T15:22:06Z",
      "side": 1,
      "message": "using \u0027atomic\u0027 for opengl test plan wouldn\u0027t work :( https://lkft.validation.linaro.org/scheduler/job/126333\n\nI don\u0027t have any use cases here. If it works for you, maybe it is fine to get it merged. I will leave it to Milosz to decide. sorry milosz :)\n\nFrom my point of view, reading CTS LAVA job\u0027s test log to collect test failures is painful, I would rather go to test attachment and check result.xml, firefox can render a beautiful webpage for that.",
      "parentUuid": "556fe32c_7646f92b",
      "revId": "4945e8ecea064085ce0bd34944529bc5834b69d2",
      "serverId": "f33910f19b7abb192b83adbd000000bf",
      "unresolved": false
    }
  ]
}